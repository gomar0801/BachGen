{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e63ce4-929c-4f28-a294-37c6689a7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "from symusic import Score\n",
    "\n",
    "# Create tokenizer with configuration\n",
    "config = TokenizerConfig(num_velocities=16, use_chords=True, use_programs=True)\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "# Convert MusicXML to tokens\n",
    "midi = Score(\"musicxml_sample/minimal.musicxml\") \n",
    "tokens = tokenizer(midi)\n",
    "\n",
    "# Train BPE for efficiency\n",
    "tokenizer.train(vocab_size=30000, files_paths=files_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ed9712-d0ac-43c7-9e3b-25664d33f8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (4.54.0)\n",
      "Requirement already satisfied: filelock in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from requests->transformers) (2025.7.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting miditok\n",
      "  Downloading miditok-3.0.6.post1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.16.4 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from miditok) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from miditok) (2.3.2)\n",
      "Collecting symusic>=0.5.0 (from miditok)\n",
      "  Downloading symusic-0.5.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from miditok) (0.21.4)\n",
      "Requirement already satisfied: tqdm in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from miditok) (4.67.1)\n",
      "Requirement already satisfied: filelock in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (1.1.5)\n",
      "Collecting pySmartDL (from symusic>=0.5.0->miditok)\n",
      "  Downloading pySmartDL-1.3.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: platformdirs in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from symusic>=0.5.0->miditok) (4.3.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (2025.7.14)\n",
      "Downloading miditok-3.0.6.post1-py3-none-any.whl (159 kB)\n",
      "Downloading symusic-0.5.8-cp313-cp313-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: pySmartDL, symusic, miditok\n",
      "Successfully installed miditok-3.0.6.post1 pySmartDL-1.3.4 symusic-0.5.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install miditok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57185a1-571c-4a25-80ac-eb1ff50a2908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raphaelcousin/Library/Caches/pypoetry/virtualenvs/bachgen-UH23d-R1-py3.13/lib/python3.13/site-packages/miditok/classes.py:886: UserWarning: Argument nb_tempos has been renamed num_tempos, you should consider to updateyour code with this new argument name.\n",
      "  return cls(**input_dict, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from miditok import REMI\n",
    "from symusic import Score\n",
    "\n",
    "# Load the pretrained tokenizer\n",
    "tokenizer = REMI.from_pretrained(\"Natooz/Maestro-REMI-bpe20k\")\n",
    "\n",
    "# Use with model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Natooz/Maestro-REMI-bpe20k\", \n",
    "                                           trust_remote_code=True, \n",
    "                                           torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fdc7c0a-6eb9-4b5c-befa-b2f23529092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def calculate_vocabulary_explosion():\n",
    "    \"\"\"Demonstrate the combinatorial explosion problem with simple vocabularies\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"VOCABULARY SIZE EXPLOSION ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic music parameters\n",
    "    pitch_range = 88  # Piano keys (21-108)\n",
    "    velocity_levels = 32  # Common discretization\n",
    "    duration_values = 20  # Common note durations (whole, half, quarter, etc.)\n",
    "    position_values = 32  # Beat positions within a bar\n",
    "    \n",
    "    print(f\"Basic musical attributes:\")\n",
    "    print(f\"  Pitches: {pitch_range}\")\n",
    "    print(f\"  Velocities: {velocity_levels}\")\n",
    "    print(f\"  Durations: {duration_values}\")\n",
    "    print(f\"  Positions: {position_values}\")\n",
    "    \n",
    "    # Simple vocabulary approach\n",
    "    simple_vocab_size = pitch_range + velocity_levels + duration_values + position_values\n",
    "    print(f\"\\n📋 SIMPLE VOCABULARY:\")\n",
    "    print(f\"  Size (sum of attributes): {simple_vocab_size} tokens\")\n",
    "    \n",
    "    # But this doesn't capture note combinations!\n",
    "    # Each note needs ALL attributes simultaneously\n",
    "    note_combinations = pitch_range * velocity_levels * duration_values\n",
    "    print(f\"\\n💥 COMBINATORIAL EXPLOSION:\")\n",
    "    print(f\"  Possible single notes: {note_combinations:,} combinations\")\n",
    "    print(f\"  This is just for ONE note at ONE position!\")\n",
    "    \n",
    "    # Multi-note scenarios (chords, sequences)\n",
    "    chord_combinations = note_combinations ** 3  # 3-note chords\n",
    "    print(f\"  Possible 3-note chords: {chord_combinations:e} combinations\")\n",
    "    print(f\"  Storage required: {chord_combinations * 4 / (1024**3):.1f} TB just for vocabulary!\")\n",
    "    \n",
    "    return simple_vocab_size, note_combinations\n",
    "\n",
    "def demonstrate_sequence_length_problem():\n",
    "    \"\"\"Show how sequence length becomes prohibitive without BPE\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SEQUENCE LENGTH PROBLEM\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example: Simple C major scale\n",
    "    c_major_scale = [\n",
    "        (\"C4\", 60, 80, 1.0),  # Note: (name, pitch, velocity, duration)\n",
    "        (\"D4\", 62, 80, 1.0),\n",
    "        (\"E4\", 64, 80, 1.0),\n",
    "        (\"F4\", 65, 80, 1.0),\n",
    "        (\"G4\", 67, 80, 1.0),\n",
    "        (\"A4\", 69, 80, 1.0),\n",
    "        (\"B4\", 71, 80, 1.0),\n",
    "        (\"C5\", 72, 80, 2.0),\n",
    "    ]\n",
    "    \n",
    "    print(\"Example: C Major Scale (8 notes)\")\n",
    "    print(\"\\n🔴 WITHOUT BPE (Simple vocabulary):\")\n",
    "    \n",
    "    tokens_without_bpe = []\n",
    "    for i, (name, pitch, velocity, duration) in enumerate(c_major_scale):\n",
    "        note_tokens = [\n",
    "            f\"Bar_1\",\n",
    "            f\"Position_{i*2}\",  # Assuming 8th note positions\n",
    "            f\"Pitch_{pitch}\",\n",
    "            f\"Velocity_{velocity}\",\n",
    "            f\"Duration_{duration}\"\n",
    "        ]\n",
    "        tokens_without_bpe.extend(note_tokens)\n",
    "        print(f\"  Note {name}: {note_tokens}\")\n",
    "    \n",
    "    print(f\"\\nTotal tokens: {len(tokens_without_bpe)}\")\n",
    "    print(f\"Average tokens per note: {len(tokens_without_bpe) / len(c_major_scale):.1f}\")\n",
    "    \n",
    "    print(\"\\n🟢 WITH BPE (Learned patterns):\")\n",
    "    # Simulate BPE learning common patterns\n",
    "    bpe_patterns = {\n",
    "        (\"Pitch_60\", \"Velocity_80\", \"Duration_1.0\"): \"NOTE_C4_normal\",\n",
    "        (\"Pitch_62\", \"Velocity_80\", \"Duration_1.0\"): \"NOTE_D4_normal\", \n",
    "        (\"Pitch_64\", \"Velocity_80\", \"Duration_1.0\"): \"NOTE_E4_normal\",\n",
    "        (\"Position_0\", \"NOTE_C4_normal\"): \"START_C4_normal\",\n",
    "        (\"Bar_1\", \"Position_0\"): \"BAR1_POS0\",\n",
    "    }\n",
    "    \n",
    "    # This is simplified - real BPE would learn many more patterns\n",
    "    tokens_with_bpe = [\"BAR1_POS0\", \"NOTE_C4_normal\", \"Position_2\", \"NOTE_D4_normal\", \n",
    "                      \"Position_4\", \"NOTE_E4_normal\", \"Position_6\", \"Pitch_65\", \n",
    "                      \"Velocity_80\", \"Duration_1.0\"]  # Mix of BPE and base tokens\n",
    "    \n",
    "    print(f\"  Optimized tokens: {tokens_with_bpe}\")\n",
    "    print(f\"Total tokens: {len(tokens_with_bpe)}\")\n",
    "    print(f\"Reduction: {((len(tokens_without_bpe) - len(tokens_with_bpe)) / len(tokens_without_bpe) * 100):.1f}%\")\n",
    "\n",
    "def analyze_music_patterns():\n",
    "    \"\"\"Analyze why musical patterns matter for BPE\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"MUSICAL PATTERN ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Simulate a dataset of musical patterns\n",
    "    print(\"Common musical patterns that BPE can learn:\")\n",
    "    \n",
    "    patterns = {\n",
    "        \"I-V-vi-IV progression\": [\"Chord_C\", \"Chord_G\", \"Chord_Am\", \"Chord_F\"],\n",
    "        \"Ascending scale\": [\"Pitch_60\", \"Pitch_62\", \"Pitch_64\", \"Pitch_65\"],\n",
    "        \"Common rhythm\": [\"Duration_0.5\", \"Duration_0.5\", \"Duration_1.0\"],\n",
    "        \"Forte dynamics\": [\"Velocity_100\", \"Velocity_105\", \"Velocity_110\"],\n",
    "        \"Beat pattern\": [\"Position_0\", \"Position_2\", \"Position_4\", \"Position_6\"],\n",
    "    }\n",
    "    \n",
    "    print(\"\\n🎵 Frequent musical sequences in training data:\")\n",
    "    for pattern_name, tokens in patterns.items():\n",
    "        print(f\"  {pattern_name}:\")\n",
    "        print(f\"    Individual tokens: {tokens}\")\n",
    "        print(f\"    BPE could learn: '{pattern_name.replace(' ', '_').upper()}'\")\n",
    "        print(f\"    Compression: {len(tokens)} → 1 token ({len(tokens)}x reduction)\")\n",
    "    \n",
    "    # Demonstrate sparsity problem\n",
    "    print(f\"\\n📊 SPARSITY PROBLEM:\")\n",
    "    print(f\"  Most 3-token combinations appear < 5 times in dataset\")\n",
    "    print(f\"  But some combinations (like C-E-G chord) appear 1000+ times\")\n",
    "    print(f\"  BPE learns frequent patterns, ignores rare ones\")\n",
    "\n",
    "def compare_efficiency():\n",
    "    \"\"\"Compare computational efficiency\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPUTATIONAL EFFICIENCY COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Transformer complexity is O(n²) where n is sequence length\n",
    "    seq_lengths = {\n",
    "        \"Simple vocab\": 1000,\n",
    "        \"BPE vocab\": 300,\n",
    "    }\n",
    "    \n",
    "    print(\"Transformer attention complexity (O(n²)):\")\n",
    "    for method, length in seq_lengths.items():\n",
    "        complexity = length ** 2\n",
    "        relative_time = complexity / (seq_lengths[\"BPE vocab\"] ** 2)\n",
    "        print(f\"  {method:12s}: {length:4d} tokens → {complexity:,} operations ({relative_time:.1f}x time)\")\n",
    "    \n",
    "    # Memory usage\n",
    "    print(f\"\\nMemory usage (attention matrices):\")\n",
    "    for method, length in seq_lengths.items():\n",
    "        memory_mb = (length ** 2 * 4) / (1024 ** 2)  # 4 bytes per float\n",
    "        print(f\"  {method:12s}: {memory_mb:.1f} MB per layer\")\n",
    "\n",
    "def show_real_bpe_example():\n",
    "    \"\"\"Show how BPE actually works step by step for music\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BPE TRAINING PROCESS FOR MUSIC\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Simulated corpus of tokenized music\n",
    "    corpus = [\n",
    "        [\"Pitch_60\", \"Velocity_80\", \"Duration_1.0\", \"Pitch_64\", \"Velocity_80\", \"Duration_1.0\"],\n",
    "        [\"Pitch_60\", \"Velocity_80\", \"Duration_0.5\", \"Pitch_62\", \"Velocity_80\", \"Duration_0.5\"],\n",
    "        [\"Pitch_64\", \"Velocity_80\", \"Duration_1.0\", \"Pitch_67\", \"Velocity_80\", \"Duration_1.0\"],\n",
    "        [\"Pitch_60\", \"Velocity_80\", \"Duration_1.0\", \"Pitch_64\", \"Velocity_80\", \"Duration_1.0\"],\n",
    "    ]\n",
    "    \n",
    "    print(\"Step 1: Initial corpus (tokenized music pieces)\")\n",
    "    for i, piece in enumerate(corpus):\n",
    "        print(f\"  Piece {i+1}: {piece}\")\n",
    "    \n",
    "    # Count bigrams\n",
    "    bigram_counts = Counter()\n",
    "    for piece in corpus:\n",
    "        for i in range(len(piece) - 1):\n",
    "            bigram = (piece[i], piece[i+1])\n",
    "            bigram_counts[bigram] += 1\n",
    "    \n",
    "    print(f\"\\nStep 2: Count all bigrams (adjacent token pairs)\")\n",
    "    for bigram, count in bigram_counts.most_common():\n",
    "        print(f\"  {bigram}: {count} times\")\n",
    "    \n",
    "    # Most frequent merge\n",
    "    most_frequent = bigram_counts.most_common(1)[0]\n",
    "    print(f\"\\nStep 3: Merge most frequent pair\")\n",
    "    print(f\"  Merging: {most_frequent[0]} → 'Pitch_60_Velocity_80'\")\n",
    "    print(f\"  This pattern appeared {most_frequent[1]} times\")\n",
    "    \n",
    "    print(f\"\\nStep 4: Repeat process...\")\n",
    "    print(f\"  After many iterations, we get complex patterns like:\")\n",
    "    print(f\"    'C_major_triad' ← Pitch_60 + Velocity_80 + Duration_1.0 + Pitch_64 + ...\")\n",
    "    print(f\"    'eighth_note_run' ← Duration_0.5 + Duration_0.5 + Duration_0.5 + ...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be672500-4223-4a5a-826e-aa5d5bb63cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUSIC BPE vs SIMPLE VOCABULARY: COMPREHENSIVE ANALYSIS\n",
      "================================================================================\n",
      "============================================================\n",
      "VOCABULARY SIZE EXPLOSION ANALYSIS\n",
      "============================================================\n",
      "Basic musical attributes:\n",
      "  Pitches: 88\n",
      "  Velocities: 32\n",
      "  Durations: 20\n",
      "  Positions: 32\n",
      "\n",
      "📋 SIMPLE VOCABULARY:\n",
      "  Size (sum of attributes): 172 tokens\n",
      "\n",
      "💥 COMBINATORIAL EXPLOSION:\n",
      "  Possible single notes: 56,320 combinations\n",
      "  This is just for ONE note at ONE position!\n",
      "  Possible 3-note chords: 1.786438e+14 combinations\n",
      "  Storage required: 665500.0 TB just for vocabulary!\n",
      "\n",
      "============================================================\n",
      "SEQUENCE LENGTH PROBLEM\n",
      "============================================================\n",
      "Example: C Major Scale (8 notes)\n",
      "\n",
      "🔴 WITHOUT BPE (Simple vocabulary):\n",
      "  Note C4: ['Bar_1', 'Position_0', 'Pitch_60', 'Velocity_80', 'Duration_1.0']\n",
      "  Note D4: ['Bar_1', 'Position_2', 'Pitch_62', 'Velocity_80', 'Duration_1.0']\n",
      "  Note E4: ['Bar_1', 'Position_4', 'Pitch_64', 'Velocity_80', 'Duration_1.0']\n",
      "  Note F4: ['Bar_1', 'Position_6', 'Pitch_65', 'Velocity_80', 'Duration_1.0']\n",
      "  Note G4: ['Bar_1', 'Position_8', 'Pitch_67', 'Velocity_80', 'Duration_1.0']\n",
      "  Note A4: ['Bar_1', 'Position_10', 'Pitch_69', 'Velocity_80', 'Duration_1.0']\n",
      "  Note B4: ['Bar_1', 'Position_12', 'Pitch_71', 'Velocity_80', 'Duration_1.0']\n",
      "  Note C5: ['Bar_1', 'Position_14', 'Pitch_72', 'Velocity_80', 'Duration_2.0']\n",
      "\n",
      "Total tokens: 40\n",
      "Average tokens per note: 5.0\n",
      "\n",
      "🟢 WITH BPE (Learned patterns):\n",
      "  Optimized tokens: ['BAR1_POS0', 'NOTE_C4_normal', 'Position_2', 'NOTE_D4_normal', 'Position_4', 'NOTE_E4_normal', 'Position_6', 'Pitch_65', 'Velocity_80', 'Duration_1.0']\n",
      "Total tokens: 10\n",
      "Reduction: 75.0%\n",
      "\n",
      "============================================================\n",
      "MUSICAL PATTERN ANALYSIS\n",
      "============================================================\n",
      "Common musical patterns that BPE can learn:\n",
      "\n",
      "🎵 Frequent musical sequences in training data:\n",
      "  I-V-vi-IV progression:\n",
      "    Individual tokens: ['Chord_C', 'Chord_G', 'Chord_Am', 'Chord_F']\n",
      "    BPE could learn: 'I-V-VI-IV_PROGRESSION'\n",
      "    Compression: 4 → 1 token (4x reduction)\n",
      "  Ascending scale:\n",
      "    Individual tokens: ['Pitch_60', 'Pitch_62', 'Pitch_64', 'Pitch_65']\n",
      "    BPE could learn: 'ASCENDING_SCALE'\n",
      "    Compression: 4 → 1 token (4x reduction)\n",
      "  Common rhythm:\n",
      "    Individual tokens: ['Duration_0.5', 'Duration_0.5', 'Duration_1.0']\n",
      "    BPE could learn: 'COMMON_RHYTHM'\n",
      "    Compression: 3 → 1 token (3x reduction)\n",
      "  Forte dynamics:\n",
      "    Individual tokens: ['Velocity_100', 'Velocity_105', 'Velocity_110']\n",
      "    BPE could learn: 'FORTE_DYNAMICS'\n",
      "    Compression: 3 → 1 token (3x reduction)\n",
      "  Beat pattern:\n",
      "    Individual tokens: ['Position_0', 'Position_2', 'Position_4', 'Position_6']\n",
      "    BPE could learn: 'BEAT_PATTERN'\n",
      "    Compression: 4 → 1 token (4x reduction)\n",
      "\n",
      "📊 SPARSITY PROBLEM:\n",
      "  Most 3-token combinations appear < 5 times in dataset\n",
      "  But some combinations (like C-E-G chord) appear 1000+ times\n",
      "  BPE learns frequent patterns, ignores rare ones\n",
      "\n",
      "============================================================\n",
      "COMPUTATIONAL EFFICIENCY COMPARISON\n",
      "============================================================\n",
      "Transformer attention complexity (O(n²)):\n",
      "  Simple vocab: 1000 tokens → 1,000,000 operations (11.1x time)\n",
      "  BPE vocab   :  300 tokens → 90,000 operations (1.0x time)\n",
      "\n",
      "Memory usage (attention matrices):\n",
      "  Simple vocab: 3.8 MB per layer\n",
      "  BPE vocab   : 0.3 MB per layer\n",
      "\n",
      "============================================================\n",
      "BPE TRAINING PROCESS FOR MUSIC\n",
      "============================================================\n",
      "Step 1: Initial corpus (tokenized music pieces)\n",
      "  Piece 1: ['Pitch_60', 'Velocity_80', 'Duration_1.0', 'Pitch_64', 'Velocity_80', 'Duration_1.0']\n",
      "  Piece 2: ['Pitch_60', 'Velocity_80', 'Duration_0.5', 'Pitch_62', 'Velocity_80', 'Duration_0.5']\n",
      "  Piece 3: ['Pitch_64', 'Velocity_80', 'Duration_1.0', 'Pitch_67', 'Velocity_80', 'Duration_1.0']\n",
      "  Piece 4: ['Pitch_60', 'Velocity_80', 'Duration_1.0', 'Pitch_64', 'Velocity_80', 'Duration_1.0']\n",
      "\n",
      "Step 2: Count all bigrams (adjacent token pairs)\n",
      "  ('Velocity_80', 'Duration_1.0'): 6 times\n",
      "  ('Pitch_60', 'Velocity_80'): 3 times\n",
      "  ('Pitch_64', 'Velocity_80'): 3 times\n",
      "  ('Duration_1.0', 'Pitch_64'): 2 times\n",
      "  ('Velocity_80', 'Duration_0.5'): 2 times\n",
      "  ('Duration_0.5', 'Pitch_62'): 1 times\n",
      "  ('Pitch_62', 'Velocity_80'): 1 times\n",
      "  ('Duration_1.0', 'Pitch_67'): 1 times\n",
      "  ('Pitch_67', 'Velocity_80'): 1 times\n",
      "\n",
      "Step 3: Merge most frequent pair\n",
      "  Merging: ('Velocity_80', 'Duration_1.0') → 'Pitch_60_Velocity_80'\n",
      "  This pattern appeared 6 times\n",
      "\n",
      "Step 4: Repeat process...\n",
      "  After many iterations, we get complex patterns like:\n",
      "    'C_major_triad' ← Pitch_60 + Velocity_80 + Duration_1.0 + Pitch_64 + ...\n",
      "    'eighth_note_run' ← Duration_0.5 + Duration_0.5 + Duration_0.5 + ...\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: WHY SIMPLE VOCABULARIES DON'T WORK\n",
      "================================================================================\n",
      "🔴 Problems with simple vocabularies:\n",
      "  1. Combinatorial explosion (millions of possible note combinations)\n",
      "  2. Very long sequences (5+ tokens per note)\n",
      "  3. Sparsity (most combinations are rare)\n",
      "  4. No pattern capture (can't learn musical idioms)\n",
      "  5. Computational inefficiency (O(n²) transformer complexity)\n",
      "\n",
      "🟢 How BPE solves these problems:\n",
      "  1. Learns only frequent patterns (manageable vocabulary)\n",
      "  2. Compresses sequences (fewer tokens per musical idea)\n",
      "  3. Captures musical structure (chords, scales, rhythms)\n",
      "  4. Better semantic embeddings (tokens represent musical concepts)\n",
      "  5. Faster training and inference (shorter sequences)\n",
      "\n",
      "💡 Key insight: Music isn't just sequences of attributes—\n",
      "   it's sequences of MUSICAL PATTERNS that BPE can discover!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Run all analyses\"\"\"\n",
    "print(\"MUSIC BPE vs SIMPLE VOCABULARY: COMPREHENSIVE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "calculate_vocabulary_explosion()\n",
    "demonstrate_sequence_length_problem()\n",
    "analyze_music_patterns()\n",
    "compare_efficiency()\n",
    "show_real_bpe_example()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY: WHY SIMPLE VOCABULARIES DON'T WORK\")\n",
    "print(\"=\" * 80)\n",
    "print(\"🔴 Problems with simple vocabularies:\")\n",
    "print(\"  1. Combinatorial explosion (millions of possible note combinations)\")\n",
    "print(\"  2. Very long sequences (5+ tokens per note)\")\n",
    "print(\"  3. Sparsity (most combinations are rare)\")\n",
    "print(\"  4. No pattern capture (can't learn musical idioms)\")\n",
    "print(\"  5. Computational inefficiency (O(n²) transformer complexity)\")\n",
    "\n",
    "print(\"\\n🟢 How BPE solves these problems:\")\n",
    "print(\"  1. Learns only frequent patterns (manageable vocabulary)\")\n",
    "print(\"  2. Compresses sequences (fewer tokens per musical idea)\")\n",
    "print(\"  3. Captures musical structure (chords, scales, rhythms)\")\n",
    "print(\"  4. Better semantic embeddings (tokens represent musical concepts)\")\n",
    "print(\"  5. Faster training and inference (shorter sequences)\")\n",
    "\n",
    "print(f\"\\n💡 Key insight: Music isn't just sequences of attributes—\")\n",
    "print(f\"   it's sequences of MUSICAL PATTERNS that BPE can discover!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d28d2-c51d-4f6b-aba9-9f00bc1efdda",
   "metadata": {},
   "source": [
    "🎹 PITCH (0-127)\n",
    "\n",
    "What it is: How high or low the note sounds\n",
    "MIDI range: 0-127 (Middle C = 60)\n",
    "Examples:\n",
    "\n",
    "Low pitch (40): Deep bass note\n",
    "Middle pitch (60): Middle C on piano\n",
    "High pitch (96): Soprano singing high note\n",
    "\n",
    "\n",
    "\n",
    "💥 VELOCITY (1-127)\n",
    "\n",
    "What it is: How hard/loud the note is played\n",
    "MIDI range: 1-127 (0 = note off)\n",
    "Examples:\n",
    "\n",
    "Low velocity (20): Gentle whisper, soft piano\n",
    "Medium velocity (64): Normal playing\n",
    "High velocity (120): Forte, powerful strike\n",
    "\n",
    "\n",
    "\n",
    "⏱️ DURATION (in beats)\n",
    "\n",
    "What it is: How long the note plays\n",
    "Common values:\n",
    "\n",
    "0.25 = Sixteenth note (very fast)\n",
    "1.0 = Quarter note (standard beat)\n",
    "4.0 = Whole note (very long)\n",
    "\n",
    "\n",
    "\n",
    "Complete Musical Note = All Three Together\n",
    "Example: Piano melody note\n",
    "├── Pitch: 72 (C5 - high C)\n",
    "├── Velocity: 45 (soft, gentle)\n",
    "└── Duration: 2.0 (half note - sustained)\n",
    "Result: A high, soft, long note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce3793-2aa3-4a67-b5f0-63ce2bfef858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
