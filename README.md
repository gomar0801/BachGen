# ğŸ¼ BachGen â€” MusicXML â†’ Tokens â†’ GPT-2 â†’ MusicXML

Un pipeline complet pour :
1. **Convertir** des fichiers `.mxl` en `.musicxml`  
2. **Tokeniser** les partitions (MusicXML â†’ sÃ©quence de tokens textuels robustes)  
3. **Construire** un vocabulaire et encoder en IDs  
4. **EntraÃ®ner** un modÃ¨le **GPT-2** causal sur ces sÃ©quences  
5. **GÃ©nÃ©rer** de nouvelles partitions musicales et les **reconstruire** en MusicXML  

Projet rÃ©alisÃ© au **SCAI (Sorbonne Center for Artificial Intelligence)**, Ã©tÃ© 2025.

---

## ğŸš€ Installation rapide (Google Colab / local)

Dans un notebook :

```bash
!rm -rf BachGen && git clone https://github.com/gomar0801/BachGen.git
!chmod +x ./BachGen/scripts/setup.sh
!./BachGen/scripts/setup.sh
```

Puis :

```python
from bachgen.display_and_play_partition import display_and_play
display_and_play('./BachGen/musicxml_sample/minimal.musicxml')
```

---

## ğŸ“‚ Structure du dÃ©pÃ´t

```
BachGen/
â”œâ”€â”€ bachgen/                  # code source du pipeline
â”‚   â”œâ”€â”€ score_to_tokens_simplify.py   # MusicXML â†’ tokens
â”‚   â”œâ”€â”€ tokens_to_score.py            # tokens â†’ MusicXML
â”‚   â”œâ”€â”€ convert_mxl.py                # conversion .mxl â†’ .musicxml
â”‚   â”œâ”€â”€ batch_tokenize.py             # tokenisation par lot + stats
â”‚   â”œâ”€â”€ vocab_utils.py                # vocabulaire, encode/decode
â”‚   â”œâ”€â”€ training.py                   # dataset + entraÃ®nement GPT-2
â”‚   â”œâ”€â”€ generation.py                 # gÃ©nÃ©ration de partitions
â”‚   â””â”€â”€ display_and_play_partition.py # affichage/Ã©coute (music21)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                      # installation des dÃ©pendances
â”‚   â”œâ”€â”€ download_data.py              # donnÃ©es Zenodo
â”‚   â””â”€â”€ extract_archives.py           # extraction .tar.gz/.zip
â”œâ”€â”€ tests/                            # tests unitaires
â”‚   â”œâ”€â”€ test_xml_to_tokens.py
â”‚   â”œâ”€â”€ test_tokens_to_xml.py
â”‚   â”œâ”€â”€ test_roundtrip.py
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ musicxml_sample/                  # exemples MusicXML
â”œâ”€â”€ token_sample/                     # exemples tokens
â”œâ”€â”€ notebooks/                        # notebooks Colab
â”‚   â””â”€â”€ BachGen_Pipeline.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§ª Tests

Lancer tous les tests :

```bash
pytest
```

Test dâ€™un fichier spÃ©cifique :

```bash
pytest tests/test_xml_to_tokens.py -v
```

---

## ğŸ¼ Exemple de format de tokens

Exemple minimal :

```
R bar clef_treble key_natural_0 time_4/4 note_C4 len_4 L bar
```

OÃ¹ :
- `R` = main droite (portÃ©e aiguÃ«)  
- `L` = main gauche (portÃ©e grave)  
- `bar` = sÃ©paration de mesure  
- `clef_treble` = clÃ© de sol  
- `key_natural_0` = do majeur (aucun diÃ¨se/bÃ©mol)  
- `time_4/4` = signature rythmique 4/4  
- `note_C4` = note Do Ã  l'octave 4  
- `len_4` = durÃ©e de 4 temps  

---

## ğŸ“Š Tokenisation robuste + statistiques

La tokenisation gÃ¨re plusieurs cas problÃ©matiques dÃ©tectÃ©s dans ScoreTransformers :
- **Notes transparentes** (`print-object="no"`) â†’ ignorÃ©es  
- **Silences superposÃ©s Ã  des notes** â†’ ignorÃ©s  
- **Multi-voix / accords** â†’ rÃ©Ã©criture des mesures en 1 voix avec harmonisation des durÃ©es  
- **Absence de voice** â†’ ajout implicite pour consistance  

Chaque partition est analysÃ©e et un CSV est produit avec :
- `% notes transparentes ignorÃ©es`  
- `% silences superposÃ©s ignorÃ©s`  
- `% positions harmonisÃ©es, notes jouÃ©es en meme temps mais d'une durÃ©e differente harmonisÃ©es en 1 accord d'une meme durÃ©e`

Exemple de rÃ©sultats (corpus classique piano) :
- **Notes transparentes ignorÃ©es** : ~1.3 % en moyenne  
- **Silences superposÃ©s ignorÃ©s** : ~4 %  en moyenne
- **Harmonisations appliquÃ©es** : ~20 % des Ã©lÃ©ments (bÃ©mol du projet)  

---

## ğŸ¤– EntraÃ®nement GPT-2

- Dataset : partitions piano classiques (MusicXML â†’ tokens â†’ IDs)  
- Vocabulaire : ~364 tokens  
- Contexte : 1024 tokens  
- ModÃ¨le : GPT-2 (4 couches, 4 tÃªtes, 1024 dim.)  
- RÃ©sultats :
  - **Validation loss** : ~0.88  
  - **Test perplexity** : ~2.4  

---

## ğŸ¹ GÃ©nÃ©ration

Exemple : gÃ©nÃ©ration depuis BOS uniquement (fin Ã  EOS) :

```python
from bachgen.generation import generate_piece, ids_to_tokens, tokens_to_musicxml_file

piece_ids = generate_piece(
    model_dir="./final_model_gpt2_ids",
    vocab_path="data/vocab/token2id.json",
    primer_tokens=None,
    max_new_tokens=300,
    top_k=8
)

tokens = ids_to_tokens(piece_ids, "data/vocab/token2id.json", drop_specials={"[PAD]","<BOS>","<EOS>"})
tokens_to_musicxml_file(tokens, "outputs/generated.musicxml")
```

Exemple avec un **prompt** :

```python
primer = ["R", "bar", "key_flat_3", "time_4/4", "clef_treble"]
piece_ids = generate_piece(
    model_dir="./final_model_gpt2_ids",
    vocab_path="data/vocab/token2id.json",
    primer_tokens=primer,
    max_new_tokens=300,
    top_k=8
)
```

---

## ğŸ““ Notebook Colab

ğŸ‘‰ [Ouvrir le notebook sur Colab](VOTRE-LIEN-COLAB-ICI)  

Ce notebook montre le pipeline complet : download â†’ conversion â†’ tokenisation â†’ vocab/IDs â†’ entraÃ®nement â†’ gÃ©nÃ©ration.

---

## ğŸ™ Remerciements

- **SCAI â€“ Sorbonne Center for Artificial Intelligence**  
- **Corpus PDMX (Zenodo)**  
- Les communautÃ©s *music21* et *Hugging Face*
